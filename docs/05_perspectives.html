<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Fundamentals of Linguistic Data Science</title><link rel="stylesheet" href="dist/reset.css"><link rel="stylesheet" href="dist/reveal.css"><link rel="stylesheet" href="dist/theme/beige.css"><link rel="stylesheet" href="plugin/highlight/monokai.css"><div class="reveal"><div class="slides"><section data-background-image="img/perspectives.png" data-background-opacity="0.5"><h1 style="font-size:3.0em">Perspectives on Linguistic Data Science</h1><h3>John P. McCrae - University of Galway</h3><h5>Course at ESSLLI 2023</h5><img src="img/uog.svg" style="position:absolute;left:70%;top:110%;width:500px;"></section><section data-background-image="img/social_media_1.png" data-background-opacity="0.5"><h1>Social Media Analytics</h1></section><section><h2>Social Media - Enterprise</h2><img src="img/twitter_sentiment.webp"><small>Image source: https://monkeylearn.com/blog/sentiment-analysis-of-twitter/ </small></section><section><h2>Social Media - Politics</h2><img src="img/elections.jpg" width="70%"><small>Image source: https://www.forbes.com/sites/waynerash/2020/09/29/new-big-data-sentiment-analysis-show-potential-biden-election-landslide/</small></section><section><h2>Ethical Data Collection</h2><ul><li>Copyright</li><li>Data Protection/Privacy</li><li>Bias (gender, race, sexuality, ...)</li><li>Represntativeness</li></ul></section><section><h2>Data Collection</h2><ul><li>API</li><li>Web Scraping</li><li>Crowdsourcing</li><li>Data Purchase</li></ul></section><section><h2>Noisy User-Generated Content</h2><ul><li>Spelling</li><li>Grammar</li><li>Slang</li><li>Emojis</li><li>Code-mixing</li></ul></section><section data-background-image="img/emotions.png" data-background-opacity="0.5"><h1>Sentiment, Emotion, Sarcasm</h1></section><section><h2>Sentiment Analysis</h2><ul><li>Predicting sentiment of text</li><li>Binary (positive/negative) or graded (0-5)</li></ul></section><section><h2>Challenges of Sentiment Analysis</h2><ul><li>Indirectness: "Although the product is disliked by many, it is still popular"</li><li>Ambiguity: "The concert was crazy" vs. "The traffic was crazy"</li><li>Irony: "I love it when my flight is delayed"</li><li>Negation: "I don't like it"</li></ul></section><section><h2>Lexicon Approaches</h2><p>Generate a lexicon of positive and negative words</p><p>Use counts to evaluate sentiment</p><table><tr><th>Positive</th><th>Negative</th></tr><tr><td>good</td><td>bad</td></tr><tr><td>great</td><td>terrible</td></tr><tr><td>excellent</td><td>awful</td></tr><tr><td>...</td><td>...</td></tr></table></section><section><h2>SentiWordNet</h2><img src="img/sentiwordnet.png"></section><section><h2>Machine Learning Approaches - Features</h2><ul><li>Sentiment features (sentiment lexicon)</li><li>Linguistic features (n-grams, ...)</li><li>Social Media features (hashtags, emoticons, …)</li><li>Other features (negation)</li><li>Feature selection and weighting (occurrence (binary), freq, PMI, TF-IDF)</li></ul></section><section><h2>Machine Learning Approaches - Deep Learning</h2><ul><li>Deep neural networks (LSTM, transformer, ...)</li><li>Pre-trained Language Models</li><li>Prompt-based Learning</li></ul></section><section><h2>Aspect-Based Sentiment Analysis</h2><p>"The camera’s focus was bad, but has a great size and is easy-to-use."</p><p>Aspects:</p><ul><li>Focus (negative)</li><li>Size (positive)</li><li>Ease-of-use (positive)</li></ul></section><section><h2>Emotion Analysis</h2><ul style="font-size:0.9em"><li>Emotion</li><ul><li>angry, sad, joyful, fearful, ashamed, proud, elated</li></ul><li>Mood</li><ul><li>cheerful, gloomy, irritable, listless, depressed, buoyant</li></ul><li>Interpersonal stances</li><ul><li>friendly, flirtatious, distant, cold, warm, supportive, contemptuous</li></ul><li>Attitudes</li><ul><li>liking, loving, hating, valuing, desiring</li></ul><li>Personality traits</li><ul><li>nervous, anxious, reckless, morose, hostile, jealous</li></ul></ul></section><section><h2>Emotion models - Ekman</h2><img src="img/ekman.jpg" width="50%"><small>Source: https://sites.tufts.edu/emotiononthebrain/2014/12/08/am-i-in-trouble-interpreting-facial-expressions/</small></section><section><h2>Emotion models - Plutchik</h2><div><img src="img/plutchik.webp" width="50%"></div><small>Source: Machine Elf 1735 (public domain)</small></section><section><h2>Emotion models - Lövheim (VAD)</h2><img src="img/vad.jpg" width="50%"><small>Source: Mitrut et al. (2019) Emotion Classification Based on Biophysical Signals and Machine Learning Techniques</small></section><section><h1>Hands-on: Sarcasm Detection</h1></section><section data-background-image="img/distant_reading.png" data-background-opacity="0.5"><h1>Distant Reading</h1></section><section><h2>Close vs Distance Reading</h2><ul><li>Close reading is the traditional way of reading a text</li><li>Distant reading uses computational methods to analyse canons of text</li><li>Term attributed to Franco Moretti (2000)</li></ul><p style="font-size:0.7em;">"So far as the engines of history are concerned, meaning does not matter. In principle, one could study the history of a literary tradition without reading any of literature. ... the main virtue of the computerized content analysis methods I use is that they save one from actually having to read the literature" - Martindale</p></section><section><h2>"The Great Unread"</h2><ul><li>Thousands of books published in 19th century England</li><li>Only a few studied now by famous authors</li><li>Computational techniques can reveal trends</li><ul><li>Titles became shorter</li><li>Text became less abstract</li></ul></ul></section><section><h4>Analysis methods for Distant Reading - Diachronic Frequency Analysis</h4><img src="img/presidents_freq.png" width="65%"><small>Source: Figure 1.4.1 – The Atlantic’s “The Language of the State of the Union” © Benjamin Schmidt, Mitch Fraa, Chris Barna, Libby Bawcombe, Noah Gordon, Betsy Ebersole, Jennie Rothenberg Gritz </small></section><section><h4>Analysis methods for Distant Reading - Lexical Diversity</h4><img src="img/hip_hop_vocab.png" width="90%"><small>Source: Matt Daniels</small></section><section><h4>Analysis methods for Distant Reading - Topic Modelling</h4><img src="img/topic_modelling.png"></section><section><h2>Narrative Analysis</h2><ul><li>Content (topics, characters, events, ...)</li><li>Structure (plot, character relationsships, ...)</li><li>Discourse (narrator, style, ...)</li></ul><p>Approach: collect text, annotate, analyse</p></section><section data-background-image="img/network_of_language.png" data-background-opacity="0.5"> <h1>Linguistic Linked Data</h1></section><section><h2>Structured and Unstructured Data</h2><ul><li>Unstructuted data is text, images, audio, video, ...</li><li>Structured data is data in a database</li><li>Lots of knowledge, especially in graph form</li></ul></section><section><h2>Wikidata</h2><p>Massive knowledge base</p><a href="https://www.wikidata.org/wiki/Q437">Q437</a></section><section><h2>Linked Data</h2><img src="img/linked_data_principles.svg"></section><section><div style="width:30%;float:left"><h2>Linked Open Data Cloud</h2></div><div style="width:70%;float:left"><img src="img/lod-cloud-sm.jpg" width="80%"></div></section><section><div style="width:30%;float:left"><h2>Linguistic Linked Open Data Cloud</h2></div><div style="width:70%;float:left"><img src="img/linguistic-lod.png" width="80%"></div></section><section><h2>Promise of Linguistic Linked Data</h2><ul><li>Representation and Modelling</li><li>Structural Interoperability</li><li>Federation </li><li>Ecosystem </li><li>Expressivity </li><li>Conceptual Interoperability </li><li>Dynamic Import </li></ul></section><section><h2>Interoperability</h2><p>Different annotation schemes</p><table style="font-size:0.7em;"><tr><td>			</td><td>Susanne	</td><td>Penn</td></tr><tr><td>The			</td><td>AT			</td><td>DT</td></tr><tr><td>Fulton		</td><td>NP1s		</td><td>NNP</td></tr><tr><td>County		</td><td>NNL1cb		</td><td>NNP</td></tr><tr><td>Grand		</td><td>JJ			</td><td>NNP</td></tr><tr><td>Jury		</td><td>NN1c		</td><td>NNP</td></tr><tr><td>said		</td><td>VVDv		</td><td>VBD</td></tr><tr><td>Friday		</td><td>NPD1		</td><td>NNP</td></tr></table></section><section><h2>NLP Interchange Format</h2><img src="img/nif.png" width="80%"></section><section><h2>OntoLex-Lemon - Lexicon Model for Ontologies</h2><img src="img/ontolex.svg"></section><section data-background-image="img/curtain_call.png" data-background-opacity="0.5"><h1>Summary</h1></section><section><h2>Summary</h2><ul><li>Social media is an important data source (but be careful!)</li><li>Sentiment and emotion analysis is achieving good performance</li><li>Computers can now tackle the "great unread"</li><li>Linking data can increase interoperability and usabilty</li></ul></section><section><h2>Thank you for attending the course!</h2><p>Feel free to contact me at <a href="mailto:john@mccr.ae">john@mccr.ae</a> if you have any questions</p><small> <a href="index.html">Back</a></small></section></div></div><script src="dist/reveal.js"></script><script src="plugin/notes/notes.js"></script><script src="plugin/markdown/markdown.js"></script><script src="plugin/highlight/highlight.js"></script><script src="plugin/math/math.js"></script><script>// More info about initialization & config:
// - https://revealjs.com/initialization/
// - https://revealjs.com/config/
Reveal.initialize({
        hash: true,
        slideNumber: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
});</script></head></html>